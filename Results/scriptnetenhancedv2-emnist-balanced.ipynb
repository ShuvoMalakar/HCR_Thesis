{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10705,"sourceType":"datasetVersion","datasetId":7160}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, SeparableConv2D, MaxPooling2D, BatchNormalization,\n                                     Activation, Dropout, Flatten, Dense)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\n\n# ----------------------------\n# 1. Improved ScriptNetEnhancedV2\n# ----------------------------\ndef build_scriptnet_enhanced(input_shape=(32, 32, 1), num_classes=47):\n    inputs = Input(shape=input_shape, name='input_layer')\n\n\n    def conv_block(x, filters, kernel_size=(3, 3), pool=True):\n        x = SeparableConv2D(\n            filters, kernel_size,\n            padding='same',\n            depthwise_regularizer=l2(1e-4),\n            pointwise_regularizer=l2(1e-4)\n        )(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        if pool:\n            x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.3)(x)\n        return x\n\n\n    x = conv_block(inputs, 64)\n    x = conv_block(x, 128)\n    x = conv_block(x, 256)\n\n    x = Flatten()(x)\n    x = Dense(512, kernel_regularizer=l2(1e-4))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    outputs = Dense(num_classes, activation='softmax', name='output_layer')(x)\n\n    return Model(inputs=inputs, outputs=outputs, name='ScriptNetEnhancedV2')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:14:39.470428Z","iopub.execute_input":"2025-06-01T03:14:39.471138Z","iopub.status.idle":"2025-06-01T03:14:39.479405Z","shell.execute_reply.started":"2025-06-01T03:14:39.471114Z","shell.execute_reply":"2025-06-01T03:14:39.478673Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport cv2\nfrom tqdm import tqdm\n\n# ---------------------------------------------\n# Step 2: Convert EMNIST CSV to Image Folders (32x32)\n# ---------------------------------------------\ndef save_emnist_images(csv_path, output_dir, img_size=(32, 32)):\n    os.makedirs(output_dir, exist_ok=True)\n\n    df = pd.read_csv(csv_path, header=None)\n    labels = df.iloc[:, 0].values.astype(int)\n    images = df.iloc[:, 1:].values.reshape(-1, 28, 28).astype('uint8')\n\n    for idx, (label, image) in enumerate(tqdm(zip(labels, images), total=len(labels))):\n        label_dir = os.path.join(output_dir, str(label))\n        os.makedirs(label_dir, exist_ok=True)\n\n        # Rotate + flip to fix EMNIST orientation\n        image = np.transpose(image, (1, 0))\n        image = cv2.flip(image, 0)\n\n        # Resize to 32x32\n        image = cv2.resize(image, img_size, interpolation=cv2.INTER_AREA)\n\n        img_path = os.path.join(label_dir, f\"{idx}.png\")\n        cv2.imwrite(img_path, image)\n\n# Convert train and test CSVs to image folders\nsave_emnist_images('/kaggle/input/emnist/emnist-balanced-train.csv', 'emnist_balanced_images/train')\nsave_emnist_images('/kaggle/input/emnist/emnist-balanced-test.csv', 'emnist_balanced_images/test')\n\n# ---------------------------------------------\n# Step 2.2: Load Data with ImageDataGenerator\n# ---------------------------------------------\nimage_size = (32, 32)\ninput_shape = (32, 32, 1)\nbatch_size = 64\nepochs = 60\nnum_classes = 47  # Update if using fewer classes\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    shear_range=0.1,\n    brightness_range=(0.9, 1.1),\n    validation_split=0.2\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    'emnist_balanced_images/train',\n    target_size=image_size,\n    color_mode='grayscale',\n    batch_size=batch_size,\n    class_mode='categorical',  # change from 'sparse' to 'categorical'\n    subset='training',\n    seed=42,\n    shuffle=True\n)\n\nval_generator = val_datagen.flow_from_directory(\n    'emnist_balanced_images/train',\n    target_size=image_size,\n    color_mode='grayscale',\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    seed=42,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:14:47.119620Z","iopub.execute_input":"2025-06-01T03:14:47.119914Z","iopub.status.idle":"2025-06-01T03:15:25.106840Z","shell.execute_reply.started":"2025-06-01T03:14:47.119891Z","shell.execute_reply":"2025-06-01T03:15:25.106035Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 112800/112800 [00:21<00:00, 5284.44it/s]\n100%|██████████| 18800/18800 [00:03<00:00, 4701.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 90240 images belonging to 47 classes.\nFound 22560 images belonging to 47 classes.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.layers import SeparableConv2D\n\n# ----------------------------\n# 3. Compile Model\n# ----------------------------\nmodel = build_scriptnet_enhanced(input_shape=input_shape, num_classes=num_classes)\n\nmodel.compile(optimizer=Adam(learning_rate=1e-4),\n              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:15:26.810774Z","iopub.execute_input":"2025-06-01T03:15:26.811383Z","iopub.status.idle":"2025-06-01T03:15:33.362541Z","shell.execute_reply.started":"2025-06-01T03:15:26.811356Z","shell.execute_reply":"2025-06-01T03:15:33.361743Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1748747730.616863      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748747730.617604      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"ScriptNetEnhancedV2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ScriptNetEnhancedV2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_2 (\u001b[38;5;33mSeparableConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m137\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_3 (\u001b[38;5;33mSeparableConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m8,896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_4 (\u001b[38;5;33mSeparableConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m34,176\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m2,097,664\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                  │          \u001b[38;5;34m24,111\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ separable_conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,176</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,111</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,168,824\u001b[0m (8.27 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,168,824</span> (8.27 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,166,904\u001b[0m (8.27 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,166,904</span> (8.27 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# ----------------------------\n# 4. Callbacks\n# ----------------------------\ncallbacks = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n    EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True),\n    ModelCheckpoint(\"scriptnet_emnist_best.h5\", monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n]\n\n# ----------------------------\n# 5. Train Model\n# ----------------------------\n\nsteps_per_epoch = np.ceil(train_generator.samples / batch_size).astype(int)\nvalidation_steps = np.ceil(val_generator.samples / batch_size).astype(int)\n\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:17:06.815827Z","iopub.execute_input":"2025-06-01T03:17:06.816185Z","iopub.status.idle":"2025-06-01T04:30:41.408067Z","shell.execute_reply.started":"2025-06-01T03:17:06.816162Z","shell.execute_reply":"2025-06-01T04:30:41.407343Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1748747833.102740     130 service.cc:148] XLA service 0x7c59c40161a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1748747833.107708     130 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748747833.107741     130 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748747834.094268     130 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   5/1410\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 45ms/step - accuracy: 0.0345 - loss: 4.8246","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748747842.475294     130 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1785 - loss: 3.5701\nEpoch 1: val_accuracy improved from -inf to 0.64176, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 55ms/step - accuracy: 0.1787 - loss: 3.5694 - val_accuracy: 0.6418 - val_loss: 1.8992 - learning_rate: 1.0000e-04\nEpoch 2/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4735 - loss: 2.3797\nEpoch 2: val_accuracy improved from 0.64176 to 0.76427, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 53ms/step - accuracy: 0.4736 - loss: 2.3796 - val_accuracy: 0.7643 - val_loss: 1.5723 - learning_rate: 1.0000e-04\nEpoch 3/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5994 - loss: 2.0144\nEpoch 3: val_accuracy improved from 0.76427 to 0.80173, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.5994 - loss: 2.0144 - val_accuracy: 0.8017 - val_loss: 1.4758 - learning_rate: 1.0000e-04\nEpoch 4/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6626 - loss: 1.8392\nEpoch 4: val_accuracy improved from 0.80173 to 0.82181, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.6626 - loss: 1.8392 - val_accuracy: 0.8218 - val_loss: 1.4211 - learning_rate: 1.0000e-04\nEpoch 5/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6963 - loss: 1.7435\nEpoch 5: val_accuracy improved from 0.82181 to 0.83276, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.6963 - loss: 1.7435 - val_accuracy: 0.8328 - val_loss: 1.3833 - learning_rate: 1.0000e-04\nEpoch 6/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7254 - loss: 1.6660\nEpoch 6: val_accuracy improved from 0.83276 to 0.84357, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.7254 - loss: 1.6660 - val_accuracy: 0.8436 - val_loss: 1.3552 - learning_rate: 1.0000e-04\nEpoch 7/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7424 - loss: 1.6115\nEpoch 7: val_accuracy improved from 0.84357 to 0.84588, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.7424 - loss: 1.6115 - val_accuracy: 0.8459 - val_loss: 1.3414 - learning_rate: 1.0000e-04\nEpoch 8/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7590 - loss: 1.5684\nEpoch 8: val_accuracy improved from 0.84588 to 0.85137, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.7590 - loss: 1.5684 - val_accuracy: 0.8514 - val_loss: 1.3172 - learning_rate: 1.0000e-04\nEpoch 9/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7702 - loss: 1.5348\nEpoch 9: val_accuracy improved from 0.85137 to 0.85465, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 53ms/step - accuracy: 0.7702 - loss: 1.5348 - val_accuracy: 0.8547 - val_loss: 1.2990 - learning_rate: 1.0000e-04\nEpoch 10/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7762 - loss: 1.5078\nEpoch 10: val_accuracy improved from 0.85465 to 0.85771, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.7762 - loss: 1.5078 - val_accuracy: 0.8577 - val_loss: 1.2836 - learning_rate: 1.0000e-04\nEpoch 11/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7845 - loss: 1.4832\nEpoch 11: val_accuracy improved from 0.85771 to 0.86073, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.7845 - loss: 1.4832 - val_accuracy: 0.8607 - val_loss: 1.2747 - learning_rate: 1.0000e-04\nEpoch 12/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7929 - loss: 1.4580\nEpoch 12: val_accuracy improved from 0.86073 to 0.86179, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.7929 - loss: 1.4580 - val_accuracy: 0.8618 - val_loss: 1.2551 - learning_rate: 1.0000e-04\nEpoch 13/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7990 - loss: 1.4374\nEpoch 13: val_accuracy improved from 0.86179 to 0.86356, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.7990 - loss: 1.4374 - val_accuracy: 0.8636 - val_loss: 1.2510 - learning_rate: 1.0000e-04\nEpoch 14/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8022 - loss: 1.4218\nEpoch 14: val_accuracy improved from 0.86356 to 0.86520, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8022 - loss: 1.4218 - val_accuracy: 0.8652 - val_loss: 1.2457 - learning_rate: 1.0000e-04\nEpoch 15/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8081 - loss: 1.4046\nEpoch 15: val_accuracy improved from 0.86520 to 0.86729, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 51ms/step - accuracy: 0.8081 - loss: 1.4046 - val_accuracy: 0.8673 - val_loss: 1.2333 - learning_rate: 1.0000e-04\nEpoch 16/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8116 - loss: 1.3932\nEpoch 16: val_accuracy improved from 0.86729 to 0.86800, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8116 - loss: 1.3932 - val_accuracy: 0.8680 - val_loss: 1.2271 - learning_rate: 1.0000e-04\nEpoch 17/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8140 - loss: 1.3800\nEpoch 17: val_accuracy improved from 0.86800 to 0.86862, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8140 - loss: 1.3800 - val_accuracy: 0.8686 - val_loss: 1.2181 - learning_rate: 1.0000e-04\nEpoch 18/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8163 - loss: 1.3699\nEpoch 18: val_accuracy improved from 0.86862 to 0.87057, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8163 - loss: 1.3699 - val_accuracy: 0.8706 - val_loss: 1.2049 - learning_rate: 1.0000e-04\nEpoch 19/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8184 - loss: 1.3610\nEpoch 19: val_accuracy improved from 0.87057 to 0.87092, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8184 - loss: 1.3610 - val_accuracy: 0.8709 - val_loss: 1.2033 - learning_rate: 1.0000e-04\nEpoch 20/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8194 - loss: 1.3522\nEpoch 20: val_accuracy improved from 0.87092 to 0.87212, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 53ms/step - accuracy: 0.8194 - loss: 1.3522 - val_accuracy: 0.8721 - val_loss: 1.1994 - learning_rate: 1.0000e-04\nEpoch 21/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8233 - loss: 1.3407\nEpoch 21: val_accuracy improved from 0.87212 to 0.87247, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8233 - loss: 1.3407 - val_accuracy: 0.8725 - val_loss: 1.1937 - learning_rate: 1.0000e-04\nEpoch 22/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8272 - loss: 1.3316\nEpoch 22: val_accuracy improved from 0.87247 to 0.87469, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8272 - loss: 1.3316 - val_accuracy: 0.8747 - val_loss: 1.1846 - learning_rate: 1.0000e-04\nEpoch 23/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8304 - loss: 1.3197\nEpoch 23: val_accuracy did not improve from 0.87469\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 51ms/step - accuracy: 0.8304 - loss: 1.3197 - val_accuracy: 0.8729 - val_loss: 1.1814 - learning_rate: 1.0000e-04\nEpoch 24/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8329 - loss: 1.3151\nEpoch 24: val_accuracy did not improve from 0.87469\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 51ms/step - accuracy: 0.8329 - loss: 1.3151 - val_accuracy: 0.8747 - val_loss: 1.1754 - learning_rate: 1.0000e-04\nEpoch 25/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8333 - loss: 1.3109\nEpoch 25: val_accuracy improved from 0.87469 to 0.87673, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8333 - loss: 1.3109 - val_accuracy: 0.8767 - val_loss: 1.1686 - learning_rate: 1.0000e-04\nEpoch 26/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8321 - loss: 1.3033\nEpoch 26: val_accuracy did not improve from 0.87673\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8321 - loss: 1.3033 - val_accuracy: 0.8766 - val_loss: 1.1705 - learning_rate: 1.0000e-04\nEpoch 27/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8349 - loss: 1.2951\nEpoch 27: val_accuracy did not improve from 0.87673\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 51ms/step - accuracy: 0.8349 - loss: 1.2951 - val_accuracy: 0.8762 - val_loss: 1.1667 - learning_rate: 1.0000e-04\nEpoch 28/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8356 - loss: 1.2945\nEpoch 28: val_accuracy improved from 0.87673 to 0.87775, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8356 - loss: 1.2945 - val_accuracy: 0.8777 - val_loss: 1.1582 - learning_rate: 1.0000e-04\nEpoch 29/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8379 - loss: 1.2879\nEpoch 29: val_accuracy did not improve from 0.87775\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 53ms/step - accuracy: 0.8379 - loss: 1.2879 - val_accuracy: 0.8774 - val_loss: 1.1612 - learning_rate: 1.0000e-04\nEpoch 30/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8407 - loss: 1.2791\nEpoch 30: val_accuracy did not improve from 0.87775\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8407 - loss: 1.2791 - val_accuracy: 0.8770 - val_loss: 1.1566 - learning_rate: 1.0000e-04\nEpoch 31/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8418 - loss: 1.2721\nEpoch 31: val_accuracy improved from 0.87775 to 0.87810, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8418 - loss: 1.2721 - val_accuracy: 0.8781 - val_loss: 1.1526 - learning_rate: 1.0000e-04\nEpoch 32/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8414 - loss: 1.2716\nEpoch 32: val_accuracy improved from 0.87810 to 0.87965, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8414 - loss: 1.2716 - val_accuracy: 0.8797 - val_loss: 1.1458 - learning_rate: 1.0000e-04\nEpoch 33/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8407 - loss: 1.2683\nEpoch 33: val_accuracy did not improve from 0.87965\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8407 - loss: 1.2683 - val_accuracy: 0.8781 - val_loss: 1.1535 - learning_rate: 1.0000e-04\nEpoch 34/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8416 - loss: 1.2627\nEpoch 34: val_accuracy did not improve from 0.87965\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8416 - loss: 1.2627 - val_accuracy: 0.8793 - val_loss: 1.1401 - learning_rate: 1.0000e-04\nEpoch 35/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8451 - loss: 1.2569\nEpoch 35: val_accuracy improved from 0.87965 to 0.87988, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 51ms/step - accuracy: 0.8451 - loss: 1.2569 - val_accuracy: 0.8799 - val_loss: 1.1384 - learning_rate: 1.0000e-04\nEpoch 36/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8474 - loss: 1.2485\nEpoch 36: val_accuracy improved from 0.87988 to 0.88076, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8474 - loss: 1.2485 - val_accuracy: 0.8808 - val_loss: 1.1354 - learning_rate: 1.0000e-04\nEpoch 37/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8456 - loss: 1.2511\nEpoch 37: val_accuracy improved from 0.88076 to 0.88218, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 51ms/step - accuracy: 0.8456 - loss: 1.2511 - val_accuracy: 0.8822 - val_loss: 1.1290 - learning_rate: 1.0000e-04\nEpoch 38/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8484 - loss: 1.2418\nEpoch 38: val_accuracy did not improve from 0.88218\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 53ms/step - accuracy: 0.8484 - loss: 1.2418 - val_accuracy: 0.8815 - val_loss: 1.1305 - learning_rate: 1.0000e-04\nEpoch 39/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8470 - loss: 1.2446\nEpoch 39: val_accuracy improved from 0.88218 to 0.88245, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8470 - loss: 1.2446 - val_accuracy: 0.8824 - val_loss: 1.1296 - learning_rate: 1.0000e-04\nEpoch 40/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8501 - loss: 1.2405\nEpoch 40: val_accuracy did not improve from 0.88245\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8501 - loss: 1.2405 - val_accuracy: 0.8817 - val_loss: 1.1246 - learning_rate: 1.0000e-04\nEpoch 41/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8489 - loss: 1.2384\nEpoch 41: val_accuracy did not improve from 0.88245\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8489 - loss: 1.2384 - val_accuracy: 0.8817 - val_loss: 1.1246 - learning_rate: 1.0000e-04\nEpoch 42/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8521 - loss: 1.2307\nEpoch 42: val_accuracy did not improve from 0.88245\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8521 - loss: 1.2307 - val_accuracy: 0.8824 - val_loss: 1.1243 - learning_rate: 1.0000e-04\nEpoch 43/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8494 - loss: 1.2333\nEpoch 43: val_accuracy improved from 0.88245 to 0.88324, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8494 - loss: 1.2333 - val_accuracy: 0.8832 - val_loss: 1.1189 - learning_rate: 1.0000e-04\nEpoch 44/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8526 - loss: 1.2288\nEpoch 44: val_accuracy did not improve from 0.88324\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8526 - loss: 1.2288 - val_accuracy: 0.8831 - val_loss: 1.1177 - learning_rate: 1.0000e-04\nEpoch 45/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8549 - loss: 1.2230\nEpoch 45: val_accuracy improved from 0.88324 to 0.88342, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8549 - loss: 1.2230 - val_accuracy: 0.8834 - val_loss: 1.1121 - learning_rate: 1.0000e-04\nEpoch 46/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8515 - loss: 1.2244\nEpoch 46: val_accuracy did not improve from 0.88342\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8515 - loss: 1.2244 - val_accuracy: 0.8829 - val_loss: 1.1191 - learning_rate: 1.0000e-04\nEpoch 47/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8520 - loss: 1.2210\nEpoch 47: val_accuracy did not improve from 0.88342\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 53ms/step - accuracy: 0.8520 - loss: 1.2210 - val_accuracy: 0.8829 - val_loss: 1.1187 - learning_rate: 1.0000e-04\nEpoch 48/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8543 - loss: 1.2159\nEpoch 48: val_accuracy improved from 0.88342 to 0.88453, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 51ms/step - accuracy: 0.8543 - loss: 1.2159 - val_accuracy: 0.8845 - val_loss: 1.1111 - learning_rate: 1.0000e-04\nEpoch 49/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8535 - loss: 1.2166\nEpoch 49: val_accuracy did not improve from 0.88453\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 51ms/step - accuracy: 0.8535 - loss: 1.2166 - val_accuracy: 0.8831 - val_loss: 1.1113 - learning_rate: 1.0000e-04\nEpoch 50/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8549 - loss: 1.2171\nEpoch 50: val_accuracy did not improve from 0.88453\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8549 - loss: 1.2171 - val_accuracy: 0.8830 - val_loss: 1.1087 - learning_rate: 1.0000e-04\nEpoch 51/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8562 - loss: 1.2145\nEpoch 51: val_accuracy did not improve from 0.88453\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8562 - loss: 1.2145 - val_accuracy: 0.8835 - val_loss: 1.1096 - learning_rate: 1.0000e-04\nEpoch 52/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8547 - loss: 1.2107\nEpoch 52: val_accuracy improved from 0.88453 to 0.88528, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8547 - loss: 1.2107 - val_accuracy: 0.8853 - val_loss: 1.1016 - learning_rate: 1.0000e-04\nEpoch 53/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8567 - loss: 1.2086\nEpoch 53: val_accuracy did not improve from 0.88528\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8567 - loss: 1.2086 - val_accuracy: 0.8842 - val_loss: 1.1032 - learning_rate: 1.0000e-04\nEpoch 54/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8590 - loss: 1.2049\nEpoch 54: val_accuracy improved from 0.88528 to 0.88533, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8590 - loss: 1.2049 - val_accuracy: 0.8853 - val_loss: 1.1028 - learning_rate: 1.0000e-04\nEpoch 55/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8596 - loss: 1.2028\nEpoch 55: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 55: val_accuracy did not improve from 0.88533\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8596 - loss: 1.2028 - val_accuracy: 0.8842 - val_loss: 1.1033 - learning_rate: 1.0000e-04\nEpoch 56/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8597 - loss: 1.1980\nEpoch 56: val_accuracy improved from 0.88533 to 0.88626, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 53ms/step - accuracy: 0.8597 - loss: 1.1980 - val_accuracy: 0.8863 - val_loss: 1.0959 - learning_rate: 5.0000e-05\nEpoch 57/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8617 - loss: 1.1899\nEpoch 57: val_accuracy improved from 0.88626 to 0.88710, saving model to scriptnet_emnist_best.h5\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 51ms/step - accuracy: 0.8617 - loss: 1.1899 - val_accuracy: 0.8871 - val_loss: 1.0972 - learning_rate: 5.0000e-05\nEpoch 58/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8621 - loss: 1.1887\nEpoch 58: val_accuracy did not improve from 0.88710\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 52ms/step - accuracy: 0.8621 - loss: 1.1887 - val_accuracy: 0.8871 - val_loss: 1.0922 - learning_rate: 5.0000e-05\nEpoch 59/60\n\u001b[1m1409/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8634 - loss: 1.1826\nEpoch 59: val_accuracy did not improve from 0.88710\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8634 - loss: 1.1826 - val_accuracy: 0.8862 - val_loss: 1.0921 - learning_rate: 5.0000e-05\nEpoch 60/60\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8620 - loss: 1.1849\nEpoch 60: val_accuracy did not improve from 0.88710\n\u001b[1m1410/1410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 52ms/step - accuracy: 0.8620 - loss: 1.1849 - val_accuracy: 0.8863 - val_loss: 1.0890 - learning_rate: 5.0000e-05\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot Accuracy\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\n# Plot Loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T04:31:18.934161Z","iopub.execute_input":"2025-06-01T04:31:18.934420Z","iopub.status.idle":"2025-06-01T04:31:19.167686Z","shell.execute_reply.started":"2025-06-01T04:31:18.934400Z","shell.execute_reply":"2025-06-01T04:31:19.166432Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1217/520360971.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# plot the convergence, in terms of accuracy and loss, of ScriptNet\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Predict labels\ny_pred_probs = model.predict(val_generator)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# True labels\ny_true = val_generator.classes\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=val_generator.class_indices.keys())\nplt.figure(figsize=(12, 12))\ndisp.plot(cmap='Blues', xticks_rotation=90)\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# true and predicted labels\ncm = confusion_matrix(y_true, y_pred, labels=range(47))\ncm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(cm_normalized, annot=False, cmap='viridis')\nplt.title('Normalized Confusion Matrix')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(30, 25))  # Bigger figure\nsns.heatmap(cm, annot=False, cmap='Blues', cbar=True)\nplt.title('Confusion Matrix (84 Classes)')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.xticks(ticks=range(0, 47, 5), labels=range(0, 47, 5), rotation=90)  # Sparse ticks\nplt.yticks(ticks=range(0, 47, 5), labels=range(0, 47, 5))\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n\n# Predict and true labels (already obtained previously)\ny_pred_probs = model.predict(val_generator)\ny_pred = np.argmax(y_pred_probs, axis=1)\ny_true = val_generator.classes\nclass_names = list(val_generator.class_indices.keys())\n\n# Print classification report\nreport = classification_report(y_true, y_pred, target_names=class_names, digits=4)\nprint(\"📋 Classification Report:\\n\")\nprint(report)\n\n# Extract and print macro, weighted scores\nprecision_macro = precision_score(y_true, y_pred, average='macro')\nrecall_macro = recall_score(y_true, y_pred, average='macro')\nf1_macro = f1_score(y_true, y_pred, average='macro')\n\nprecision_weighted = precision_score(y_true, y_pred, average='weighted')\nrecall_weighted = recall_score(y_true, y_pred, average='weighted')\nf1_weighted = f1_score(y_true, y_pred, average='weighted')\n\nprint(\"🔢 Macro Scores\")\nprint(f\"Precision (Macro): {precision_macro:.4f}\")\nprint(f\"Recall (Macro):    {recall_macro:.4f}\")\nprint(f\"F1-score (Macro):  {f1_macro:.4f}\")\n\nprint(\"\\n🔢 Weighted Scores\")\nprint(f\"Precision (Weighted): {precision_weighted:.4f}\")\nprint(f\"Recall (Weighted):    {recall_weighted:.4f}\")\nprint(f\"F1-score (Weighted):  {f1_weighted:.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now exit the session\nimport os\nos._exit(0)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-01T04:31:01.375Z"}},"outputs":[],"execution_count":null}]}